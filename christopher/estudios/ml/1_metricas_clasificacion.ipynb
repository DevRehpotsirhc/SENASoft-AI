{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4add73a2",
   "metadata": {},
   "source": [
    "# Métricas de Clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da4f21fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\"\"\"\n",
    "Estas métricas se usan para saber la precisión de los modelos \n",
    "entrenados (no hace referencia a la IA, se basa en predicción)\n",
    "todo ello a nivel estádistico, buscando una baja dispersión y \n",
    "un bajo sesgo, es decir, que el modelo no sea demasiado simple\n",
    "ni que haya demasiada varianza en las predicciones\n",
    "\"\"\"\n",
    "\n",
    "# Esta métrica muestra la precisión de los datos, es decir, el rango que se acertó con las predicciones\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Esta métrica muestra la matriz de los datos acertados entre positivos(1) y negativos(0) en cantidades\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# Muestra un reporte completo de cuántos datos había, qué porcentaje se acertó, y una vista globalizada\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246d64fd",
   "metadata": {},
   "source": [
    "### Accuracy (Precisión)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37aff371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejemplo de datos PLANOS\n",
    "y_true = [1, 0, 1, 1, 0]\n",
    "# Ejemplo de datos predecidos\n",
    "y_pred = [1, 0, 1, 0, 0]\n",
    "\n",
    "accuracy_score(y_true, y_pred)  # Muestra porcentaje de predicción\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bca88f",
   "metadata": {},
   "source": [
    "### Matriz de Confusión Binaria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82aaec92",
   "metadata": {},
   "source": [
    "Se organiza en:\n",
    "\n",
    "\n",
    "<table border=\"1\" cellpadding=\"8\" cellspacing=\"0\">\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th></th>\n",
    "      <th colspan=\"2\">Predicho</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Real</th>\n",
    "      <th>0</th>\n",
    "      <th>1</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>Verdadero negativo</td>\n",
    "      <td>Falso positivo</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>Falso negativo</td>\n",
    "      <td>Verdadero positivo</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33fcbd54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verdadero negativo: 2\n",
      "Falso positivo: 0\n",
      "Falso negativo: 1\n",
      "Verdadero positivo: 2\n"
     ]
    }
   ],
   "source": [
    "# En este caso es una clásificación binaria (0, 1)\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()        # Ravel le quita una dimensión al array\n",
    "print(f\"Verdadero negativo: {tn}\\nFalso positivo: {fp}\\nFalso negativo: {fn}\\nVerdadero positivo: {tp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "089e7c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0],\n",
       "       [1, 2]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# También se puede correr como un array\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebdfc4e",
   "metadata": {},
   "source": [
    "### Matriz de Confusión Multiclase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1092d8",
   "metadata": {},
   "source": [
    "Esta matriz crea una fila y una columna que corresponde a <strong>un valor dentro de los datos</strong> que tiene, no importa cuántas veces se repita ese valor dentro de los datos, él toma un único valor y los compara con los demás según la posición que ocupe dentro de la matriz\n",
    "\n",
    "Dicho de otra manera, va a comparar <strong>cuántas veces</strong> un valor es predicho como ese mismo valor o como cualquiera que esté en el array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "476ccf56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0],\n",
       "       [1, 1, 0, 0],\n",
       "       [0, 0, 1, 2],\n",
       "       [0, 0, 0, 1]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejemplo de datos PLANOS\n",
    "x_true = [1, 0, \"h\", 1, 2, 2, 2]\n",
    "# Ejemplo de datos predecidos\n",
    "x_pred = [1, 0, \"h\", 0, \"h\", \"h\", 2]\n",
    "\n",
    "# Clasificación multiclase\n",
    "confusion_matrix(x_true, x_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d5b04b",
   "metadata": {},
   "source": [
    "### Reporte de Clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ff2e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         1\n",
      "           1       1.00      0.50      0.67         2\n",
      "           2       1.00      0.33      0.50         3\n",
      "           h       0.33      1.00      0.50         1\n",
      "\n",
      "    accuracy                           0.57         7\n",
      "   macro avg       0.71      0.71      0.58         7\n",
      "weighted avg       0.83      0.57      0.57         7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(x_true, x_pred))\n",
    "\"\"\"\n",
    "precision: marca todas las veces que se llamo una clase vs cuántas se acertó a nivel estadístico\n",
    "\n",
    "recall: mide si las veces que se llamó la clase cumple con las veces que existe en los datos (no importa si sobrepasa el número de veces siempre que cumpla con la cantidad)\n",
    "\n",
    "f1-score: compara precision vs recall a nivel estadístico\n",
    "\n",
    "support: conteo de veces que existe la clase en los datos\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
