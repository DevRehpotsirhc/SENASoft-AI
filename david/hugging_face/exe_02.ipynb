{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea605a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9365acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9a6684",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_ana =  data[data[\"nombre\"] == \"Ana\"]\n",
    "nombre_ana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905899c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas = data.columns.to_list()\n",
    "columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68891360",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parametro_busqueda_keyword(parametro):\n",
    "    res =  data[parametro]\n",
    "    print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defaee30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def user_input(debug):\n",
    "\n",
    "    if debug:\n",
    "        return \"muestrame algunos nombres\"\n",
    "    else:\n",
    "        text_input = widgets.Text(\n",
    "            value='',\n",
    "            description='Tu pregunta:',\n",
    "            placeholder='Escribe tu pregunta aquí'\n",
    "        )\n",
    "        \n",
    "        display(text_input)\n",
    "        \n",
    "        def handle_submit(sender):\n",
    "            global user_question\n",
    "            user_question = sender.value\n",
    "            clear_output()\n",
    "            print(f\"Pregunta ingresada: {user_question}\")\n",
    "        \n",
    "        text_input.observe(handle_submit, names='value')\n",
    "        \n",
    "        return text_input.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e128cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "checkpoint = \"bigscience/bloomz-1b7\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    checkpoint,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    low_cpu_mem_usage=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac686df",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_2 = f\"\"\"\n",
    "    INSTRUCCIÓN: Elige UNA palabra de esta lista [{', '.join(columnas)}] que mejor clasifique la siguiente pregunta\n",
    "    PREGUNTA: 'Quien tiene 25 años?'.\n",
    "    IMPORTANTE: Solo responde con UNA PALABRA DE LA LISTA. Nada más.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "inputs_2 = tokenizer.encode(prompt_2, return_tensors=\"pt\")\n",
    "attention_mask = torch.ones_like(inputs_2)\n",
    "\n",
    "outputs = model.generate(\n",
    "    inputs_2,\n",
    "    attention_mask=attention_mask,\n",
    "    max_new_tokens=2,\n",
    "    num_return_sequences=1,\n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    "    top_k=5,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    repetition_penalty=1.2\n",
    ")\n",
    "\n",
    "res = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5470ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"INSTRUCCIÓN: Elige UNA palabra de esta lista [{', '.join(columnas)}] que mejor clasifique la siguiente frase.\n",
    "FRASE: '{user_input(True)}'\n",
    "IMPORTANTE: Solo responde con una palabra de la lista. Nada más.\n",
    "RESPUESTA:\"\"\"\n",
    "\n",
    "inputs = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "attention_mask = torch.ones_like(inputs)\n",
    "\n",
    "outputs = model.generate(\n",
    "    inputs,\n",
    "    attention_mask=attention_mask,\n",
    "    max_new_tokens=2,\n",
    "    num_return_sequences=1,\n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    "    top_k=5,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    repetition_penalty=1.2\n",
    ")\n",
    "\n",
    "res = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "words = res.split()\n",
    "for word in reversed(words):\n",
    "    word = word.strip(\"'\\\".,!? \")\n",
    "    if word in columnas:\n",
    "        last_word = word\n",
    "        break\n",
    "    else:\n",
    "        last_word = \"nombre\"\n",
    "\n",
    "print(f\"Palabra clasificada: {last_word}\")\n",
    "parametro_busqueda_keyword(str(last_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12410ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the disk and cpu.\n",
      "Device set to use cpu\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'The key to life is not to lose yourself in the world but to find yourself in the world.\\nThe key to life is not to lose yourself in the world but to find yourself in the world. This is the key to life. The key to life is not to lose yourself in the world but to find yourself in the world. This is the key to life. This is the key to life.\\nThe key to life is not to lose yourself in the world but to find yourself in the world.\\nThe key to life is not to lose yourself in the world but to find yourself in the world.\\nThe key to life is not to lose yourself in the world but to find yourself in the world. This is the key to life. The key to life is not to lose yourself in the world but to find yourself in the world. This is the key to life. This is the key to life.\\nThe key to life is not to lose yourself in the world but to find yourself in the world.\\nThe key to life is not to lose yourself in the world but to find yourself in the world. This is the key to life. The key to life is not to lose yourself in the world but to find yourself in the world. This is the key to life. This is the key to'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.2-1B\"\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\", \n",
    "    model=model_id, \n",
    "    token=os.getenv(\"HF_LLAMA_TOKEN\"),\n",
    "    torch_dtype=torch.bfloat16, \n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "pipe(\"The key to life is\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
