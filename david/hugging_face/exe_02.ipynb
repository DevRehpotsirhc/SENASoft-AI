{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dea605a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9365acf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nombre</th>\n",
       "      <th>apellido</th>\n",
       "      <th>edad</th>\n",
       "      <th>profesion</th>\n",
       "      <th>sueldo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ana</td>\n",
       "      <td>García</td>\n",
       "      <td>28</td>\n",
       "      <td>Ingeniera de Software</td>\n",
       "      <td>45000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Carlos</td>\n",
       "      <td>Rodríguez</td>\n",
       "      <td>35</td>\n",
       "      <td>Médico</td>\n",
       "      <td>75000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Laura</td>\n",
       "      <td>Martínez</td>\n",
       "      <td>42</td>\n",
       "      <td>Abogada</td>\n",
       "      <td>62000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Javier</td>\n",
       "      <td>López</td>\n",
       "      <td>29</td>\n",
       "      <td>Diseñador Gráfico</td>\n",
       "      <td>38000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>María</td>\n",
       "      <td>Fernández</td>\n",
       "      <td>51</td>\n",
       "      <td>Profesora</td>\n",
       "      <td>48000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pedro</td>\n",
       "      <td>Sánchez</td>\n",
       "      <td>33</td>\n",
       "      <td>Contador</td>\n",
       "      <td>52000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sofía</td>\n",
       "      <td>Ramírez</td>\n",
       "      <td>26</td>\n",
       "      <td>Periodista</td>\n",
       "      <td>35000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Diego</td>\n",
       "      <td>González</td>\n",
       "      <td>45</td>\n",
       "      <td>Arquitecto</td>\n",
       "      <td>68000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Elena</td>\n",
       "      <td>Torres</td>\n",
       "      <td>39</td>\n",
       "      <td>Psicóloga</td>\n",
       "      <td>55000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Miguel</td>\n",
       "      <td>Vargas</td>\n",
       "      <td>31</td>\n",
       "      <td>Analista de Datos</td>\n",
       "      <td>58000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Isabel</td>\n",
       "      <td>Díaz</td>\n",
       "      <td>47</td>\n",
       "      <td>Enfermera</td>\n",
       "      <td>42000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Ricardo</td>\n",
       "      <td>Herrera</td>\n",
       "      <td>36</td>\n",
       "      <td>Ingeniero Civil</td>\n",
       "      <td>65000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Carmen</td>\n",
       "      <td>Ortega</td>\n",
       "      <td>29</td>\n",
       "      <td>Marketing Digital</td>\n",
       "      <td>41000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Antonio</td>\n",
       "      <td>Castro</td>\n",
       "      <td>53</td>\n",
       "      <td>Director de Proyectos</td>\n",
       "      <td>82000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Natalia</td>\n",
       "      <td>Reyes</td>\n",
       "      <td>25</td>\n",
       "      <td>Desarrolladora Web</td>\n",
       "      <td>37000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Oscar</td>\n",
       "      <td>Silva</td>\n",
       "      <td>41</td>\n",
       "      <td>Consultor Financiero</td>\n",
       "      <td>71000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Patricia</td>\n",
       "      <td>Mendoza</td>\n",
       "      <td>34</td>\n",
       "      <td>Recursos Humanos</td>\n",
       "      <td>46000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Fernando</td>\n",
       "      <td>Núñez</td>\n",
       "      <td>48</td>\n",
       "      <td>Ingeniero Mecánico</td>\n",
       "      <td>63000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Verónica</td>\n",
       "      <td>Guerrero</td>\n",
       "      <td>30</td>\n",
       "      <td>Community Manager</td>\n",
       "      <td>34000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Roberto</td>\n",
       "      <td>Jiménez</td>\n",
       "      <td>44</td>\n",
       "      <td>Gerente de Ventas</td>\n",
       "      <td>69000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      nombre   apellido  edad              profesion  sueldo\n",
       "0        Ana     García    28  Ingeniera de Software   45000\n",
       "1     Carlos  Rodríguez    35                 Médico   75000\n",
       "2      Laura   Martínez    42                Abogada   62000\n",
       "3     Javier      López    29      Diseñador Gráfico   38000\n",
       "4      María  Fernández    51              Profesora   48000\n",
       "5      Pedro    Sánchez    33               Contador   52000\n",
       "6      Sofía    Ramírez    26             Periodista   35000\n",
       "7      Diego   González    45             Arquitecto   68000\n",
       "8      Elena     Torres    39              Psicóloga   55000\n",
       "9     Miguel     Vargas    31      Analista de Datos   58000\n",
       "10    Isabel       Díaz    47              Enfermera   42000\n",
       "11   Ricardo    Herrera    36        Ingeniero Civil   65000\n",
       "12    Carmen     Ortega    29      Marketing Digital   41000\n",
       "13   Antonio     Castro    53  Director de Proyectos   82000\n",
       "14   Natalia      Reyes    25     Desarrolladora Web   37000\n",
       "15     Oscar      Silva    41   Consultor Financiero   71000\n",
       "16  Patricia    Mendoza    34       Recursos Humanos   46000\n",
       "17  Fernando      Núñez    48     Ingeniero Mecánico   63000\n",
       "18  Verónica   Guerrero    30      Community Manager   34000\n",
       "19   Roberto    Jiménez    44      Gerente de Ventas   69000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a9a6684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nombre</th>\n",
       "      <th>apellido</th>\n",
       "      <th>edad</th>\n",
       "      <th>profesion</th>\n",
       "      <th>sueldo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ana</td>\n",
       "      <td>García</td>\n",
       "      <td>28</td>\n",
       "      <td>Ingeniera de Software</td>\n",
       "      <td>45000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  nombre apellido  edad              profesion  sueldo\n",
       "0    Ana   García    28  Ingeniera de Software   45000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nombre_ana =  data[data[\"nombre\"] == \"Ana\"]\n",
    "nombre_ana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "905899c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nombre', 'apellido', 'edad', 'profesion', 'sueldo']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columnas = data.columns.to_list()\n",
    "columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68891360",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parametro_busqueda_keyword(parametro):\n",
    "    res =  data[parametro]\n",
    "    print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "defaee30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def user_input(debug):\n",
    "\n",
    "    if debug:\n",
    "        return \"muestrame algunos nombres\"\n",
    "    else:\n",
    "        text_input = widgets.Text(\n",
    "            value='',\n",
    "            description='Tu pregunta:',\n",
    "            placeholder='Escribe tu pregunta aquí'\n",
    "        )\n",
    "        \n",
    "        display(text_input)\n",
    "        \n",
    "        def handle_submit(sender):\n",
    "            global user_question\n",
    "            user_question = sender.value\n",
    "            clear_output()\n",
    "            print(f\"Pregunta ingresada: {user_question}\")\n",
    "        \n",
    "        text_input.observe(handle_submit, names='value')\n",
    "        \n",
    "        return text_input.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e128cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "checkpoint = \"bigscience/bloomz-1b7\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    checkpoint,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    low_cpu_mem_usage=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bac686df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSTRUCCIÓN: Elige UNA palabra de esta lista [nombre, apellido, edad, profesion, sueldo] que mejor clasifique la siguiente pregunta\n",
      "    PREGUNTA: 'Quien tiene 25 años?'.\n",
      "    IMPORTANTE: Solo responde con UNA PALABRA DE LA LISTA. Nada más.\n",
      " \n",
      "#\n"
     ]
    }
   ],
   "source": [
    "prompt_2 = f\"\"\"\n",
    "    INSTRUCCIÓN: Elige UNA palabra de esta lista [{', '.join(columnas)}] que mejor clasifique la siguiente pregunta\n",
    "    PREGUNTA: 'Quien tiene 25 años?'.\n",
    "    IMPORTANTE: Solo responde con UNA PALABRA DE LA LISTA. Nada más.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "inputs_2 = tokenizer.encode(prompt_2, return_tensors=\"pt\")\n",
    "attention_mask = torch.ones_like(inputs_2)\n",
    "\n",
    "outputs = model.generate(\n",
    "    inputs_2,\n",
    "    attention_mask=attention_mask,\n",
    "    max_new_tokens=2,\n",
    "    num_return_sequences=1,\n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    "    top_k=5,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    repetition_penalty=1.2\n",
    ")\n",
    "\n",
    "res = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef5470ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabra clasificada: nombre\n",
      "0          Ana\n",
      "1       Carlos\n",
      "2        Laura\n",
      "3       Javier\n",
      "4        María\n",
      "5        Pedro\n",
      "6        Sofía\n",
      "7        Diego\n",
      "8        Elena\n",
      "9       Miguel\n",
      "10      Isabel\n",
      "11     Ricardo\n",
      "12      Carmen\n",
      "13     Antonio\n",
      "14     Natalia\n",
      "15       Oscar\n",
      "16    Patricia\n",
      "17    Fernando\n",
      "18    Verónica\n",
      "19     Roberto\n",
      "Name: nombre, dtype: object\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"INSTRUCCIÓN: Elige UNA palabra de esta lista [{', '.join(columnas)}] que mejor clasifique la siguiente frase.\n",
    "FRASE: '{user_input(True)}'\n",
    "IMPORTANTE: Solo responde con una palabra de la lista. Nada más.\n",
    "RESPUESTA:\"\"\"\n",
    "\n",
    "inputs = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "attention_mask = torch.ones_like(inputs)\n",
    "\n",
    "outputs = model.generate(\n",
    "    inputs,\n",
    "    attention_mask=attention_mask,\n",
    "    max_new_tokens=2,\n",
    "    num_return_sequences=1,\n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    "    top_k=5,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    repetition_penalty=1.2\n",
    ")\n",
    "\n",
    "res = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "words = res.split()\n",
    "for word in reversed(words):\n",
    "    word = word.strip(\"'\\\".,!? \")\n",
    "    if word in columnas:\n",
    "        last_word = word\n",
    "        break\n",
    "    else:\n",
    "        last_word = \"nombre\"\n",
    "\n",
    "print(f\"Palabra clasificada: {last_word}\")\n",
    "parametro_busqueda_keyword(str(last_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b12410ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      6\u001b[39m load_dotenv()\n\u001b[32m      8\u001b[39m model_id = \u001b[33m\"\u001b[39m\u001b[33mmeta-llama/Llama-3.2-1B\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m pipe = \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext-generation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetenv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHF_LLAMA_TOKEN\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbfloat16\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     16\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m pipe(\u001b[33m\"\u001b[39m\u001b[33mThe key to life is\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\VICTUS\\Documents\\Programing_stuff_4.0\\SENASoft-AI-Learning\\david\\hugging_face\\venv\\Lib\\site-packages\\transformers\\pipelines\\__init__.py:1028\u001b[39m, in \u001b[36mpipeline\u001b[39m\u001b[34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[39m\n\u001b[32m   1026\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1027\u001b[39m     model_classes = {\u001b[33m\"\u001b[39m\u001b[33mtf\u001b[39m\u001b[33m\"\u001b[39m: targeted_task[\u001b[33m\"\u001b[39m\u001b[33mtf\u001b[39m\u001b[33m\"\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m: targeted_task[\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m]}\n\u001b[32m-> \u001b[39m\u001b[32m1028\u001b[39m     framework, model = \u001b[43minfer_framework_load_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[43m        \u001b[49m\u001b[43madapter_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43madapter_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1030\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1032\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframework\u001b[49m\u001b[43m=\u001b[49m\u001b[43mframework\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1033\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1034\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1035\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1036\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1038\u001b[39m hub_kwargs[\u001b[33m\"\u001b[39m\u001b[33m_commit_hash\u001b[39m\u001b[33m\"\u001b[39m] = model.config._commit_hash\n\u001b[32m   1040\u001b[39m \u001b[38;5;66;03m# Check which preprocessing classes the pipeline uses\u001b[39;00m\n\u001b[32m   1041\u001b[39m \u001b[38;5;66;03m# None values indicate optional classes that the pipeline can run without, we don't raise errors if loading fails\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\VICTUS\\Documents\\Programing_stuff_4.0\\SENASoft-AI-Learning\\david\\hugging_face\\venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:293\u001b[39m, in \u001b[36minfer_framework_load_model\u001b[39m\u001b[34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[39m\n\u001b[32m    287\u001b[39m     logger.warning(\n\u001b[32m    288\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mModel might be a PyTorch model (ending with `.bin`) but PyTorch is not available. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    289\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mTrying to load the model with Tensorflow.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    290\u001b[39m     )\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m     model = \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    294\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[33m\"\u001b[39m\u001b[33meval\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    295\u001b[39m         model = model.eval()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\VICTUS\\Documents\\Programing_stuff_4.0\\SENASoft-AI-Learning\\david\\hugging_face\\venv\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:604\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    602\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_class.config_class == config.sub_configs.get(\u001b[33m\"\u001b[39m\u001b[33mtext_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    603\u001b[39m         config = config.get_text_config()\n\u001b[32m--> \u001b[39m\u001b[32m604\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    605\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    606\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    608\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    609\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    610\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\VICTUS\\Documents\\Programing_stuff_4.0\\SENASoft-AI-Learning\\david\\hugging_face\\venv\\Lib\\site-packages\\transformers\\modeling_utils.py:288\u001b[39m, in \u001b[36mrestore_default_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    286\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    290\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\VICTUS\\Documents\\Programing_stuff_4.0\\SENASoft-AI-Learning\\david\\hugging_face\\venv\\Lib\\site-packages\\transformers\\modeling_utils.py:5176\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   5166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5167\u001b[39m         torch.set_default_dtype(dtype_orig)\n\u001b[32m   5169\u001b[39m     (\n\u001b[32m   5170\u001b[39m         model,\n\u001b[32m   5171\u001b[39m         missing_keys,\n\u001b[32m   5172\u001b[39m         unexpected_keys,\n\u001b[32m   5173\u001b[39m         mismatched_keys,\n\u001b[32m   5174\u001b[39m         offload_index,\n\u001b[32m   5175\u001b[39m         error_msgs,\n\u001b[32m-> \u001b[39m\u001b[32m5176\u001b[39m     ) = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5177\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5178\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5179\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5180\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5181\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5182\u001b[39m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5183\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5184\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5185\u001b[39m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5186\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5187\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5188\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5189\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5190\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5191\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5192\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5193\u001b[39m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[32m   5194\u001b[39m model.tie_weights()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\VICTUS\\Documents\\Programing_stuff_4.0\\SENASoft-AI-Learning\\david\\hugging_face\\venv\\Lib\\site-packages\\transformers\\modeling_utils.py:5597\u001b[39m, in \u001b[36mPreTrainedModel._load_pretrained_model\u001b[39m\u001b[34m(cls, model, state_dict, checkpoint_files, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, device_map, disk_offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_regex, device_mesh, key_mapping, weights_only)\u001b[39m\n\u001b[32m   5595\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_hqq_or_quark:\n\u001b[32m   5596\u001b[39m     expanded_device_map = expand_device_map(device_map, expected_keys)\n\u001b[32m-> \u001b[39m\u001b[32m5597\u001b[39m     \u001b[43mcaching_allocator_warmup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpanded_device_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5599\u001b[39m \u001b[38;5;66;03m# Prepare and compatabilize arguments for serial and parallel shard loading\u001b[39;00m\n\u001b[32m   5600\u001b[39m args_list = [\n\u001b[32m   5601\u001b[39m     (\n\u001b[32m   5602\u001b[39m         shard_file,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5623\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m shard_file \u001b[38;5;129;01min\u001b[39;00m checkpoint_files\n\u001b[32m   5624\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\VICTUS\\Documents\\Programing_stuff_4.0\\SENASoft-AI-Learning\\david\\hugging_face\\venv\\Lib\\site-packages\\transformers\\modeling_utils.py:6215\u001b[39m, in \u001b[36mcaching_allocator_warmup\u001b[39m\u001b[34m(model, expanded_device_map, hf_quantizer)\u001b[39m\n\u001b[32m   6213\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m device.type \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mxpu\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m   6214\u001b[39m     torch_accelerator_module = \u001b[38;5;28mgetattr\u001b[39m(torch, device.type)\n\u001b[32m-> \u001b[39m\u001b[32m6215\u001b[39m     index = device.index \u001b[38;5;28;01mif\u001b[39;00m device.index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mtorch_accelerator_module\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcurrent_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6216\u001b[39m     device_memory = torch_accelerator_module.mem_get_info(index)[\u001b[32m0\u001b[39m]\n\u001b[32m   6217\u001b[39m     \u001b[38;5;66;03m# Allow up to (max device memory - 1.2 GiB) in resource-constrained hardware configurations. Trying to reserve more\u001b[39;00m\n\u001b[32m   6218\u001b[39m     \u001b[38;5;66;03m# than that amount might sometimes lead to unnecessary cuda/xpu OOM, if the last parameter to be loaded on the device is large,\u001b[39;00m\n\u001b[32m   6219\u001b[39m     \u001b[38;5;66;03m# and the remaining reserved memory portion is smaller than the param size -> torch will then try to fully re-allocate all\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   6222\u001b[39m     \u001b[38;5;66;03m# Note that we use an absolute value instead of device proportion here, as a 8GiB device could still allocate too much\u001b[39;00m\n\u001b[32m   6223\u001b[39m     \u001b[38;5;66;03m# if using e.g. 90% of device size, while a 140GiB device would allocate too little\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\VICTUS\\Documents\\Programing_stuff_4.0\\SENASoft-AI-Learning\\david\\hugging_face\\venv\\Lib\\site-packages\\torch\\cuda\\__init__.py:1071\u001b[39m, in \u001b[36mcurrent_device\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1069\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcurrent_device\u001b[39m() -> \u001b[38;5;28mint\u001b[39m:\n\u001b[32m   1070\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Return the index of a currently selected device.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1071\u001b[39m     \u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1072\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch._C._cuda_getDevice()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\VICTUS\\Documents\\Programing_stuff_4.0\\SENASoft-AI-Learning\\david\\hugging_face\\venv\\Lib\\site-packages\\torch\\cuda\\__init__.py:403\u001b[39m, in \u001b[36m_lazy_init\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    398\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    399\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    400\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmultiprocessing, you must use the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mspawn\u001b[39m\u001b[33m'\u001b[39m\u001b[33m start method\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    401\u001b[39m     )\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch._C, \u001b[33m\"\u001b[39m\u001b[33m_cuda_getDeviceCount\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mTorch not compiled with CUDA enabled\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    404\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    405\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[32m    406\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    407\u001b[39m     )\n",
      "\u001b[31mAssertionError\u001b[39m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.2-1B\"\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\", \n",
    "    model=model_id, \n",
    "    token=os.getenv(\"HF_LLAMA_TOKEN\"),\n",
    "    torch_dtype=torch.bfloat16, \n",
    "    device_map=\"cuda\"\n",
    ")\n",
    "\n",
    "pipe(\"The key to life is\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
